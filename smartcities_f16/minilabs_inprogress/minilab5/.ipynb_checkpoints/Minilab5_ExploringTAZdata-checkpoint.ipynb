{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minilab 5\n",
    "In this lab you will further explore the Traffic Analysis Zone (TAZ) data that we began to explore in minilab 4. In part 1 of this lab we will look at some of the population data stored in 'data/tazData.csv' including employment, age, and income data.\n",
    "\n",
    "In part 2 you will use the Tables join() function to join the populations tazData with the travel skims data that we looked at in minilab 3. You will calculate the effect that a large event in San Francisco (e.g. a Giants Game) can have on the transportation network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datascience import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Part 1 - exploring TAZ population data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "File b'tazData.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mOSError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-06d8b9053cfa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtazData\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tazData.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtazData\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/conda/lib/python3.5/site-packages/datascience/tables.py\u001b[0m in \u001b[0;36mread_table\u001b[1;34m(cls, filepath_or_buffer, *args, **vargs)\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m         \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mvargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/conda/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    560\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    561\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 562\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    563\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    564\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/conda/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 315\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/conda/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    643\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 645\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/conda/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m    797\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    798\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 799\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    800\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    801\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/conda/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1211\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1213\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas/parser.c:3427)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas/parser.c:6861)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: File b'tazData.csv' does not exist"
     ]
    }
   ],
   "source": [
    "tazData = Table.read_table('tazData.csv')\n",
    "tazData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the TazData dictionary. It contains information on the meaning of each of the column headers. This information comes from http://analytics.mtc.ca.gov/foswiki/Main/TazData\n",
    "\n",
    "    ZONE\t    Transportation analysis zone\tInteger, 1 to 1454\tOrigins, destinations, shape file\n",
    "    DISTRICT\tSuperdistrict geographic designation\tInteger, 1 to 34\tShape file\n",
    "    SD\t        Superdistrict geographic designation (duplicate)\tInteger, 1 to 34\t \n",
    "    COUNTY\t    County\tInteger, 1 to 9\t\n",
    "                                 1 - San Francisco;\n",
    "                                 2 - San Mateo;\n",
    "                                 3 - Santa Clara;\n",
    "                                 4 - Alameda;\n",
    "                                 5 - Contra Costa;\n",
    "                                 6 - Solano;\n",
    "                                 7 - Napa;\n",
    "                                 8 - Sonoma;\n",
    "                                 9 - Marin\n",
    "    TOTHH\t    Total households\tInteger, 0 and up\t \n",
    "    HHPOP\t    Population living in households (as opposed to group quarters)\tInteger, 0 and up\t \n",
    "    TOTPOP\t    Total population\tInteger, 0 and up\t \n",
    "    EMPRES\t    Employed residents\tInteger, 0 and up\t \n",
    "    SFDU\t    Number of occupied single-family dwelling units\tInteger, 0 and up\t \n",
    "    MFDU\t    Number of occupied multi-family dwelling units\tInteger, 0 and up\t \n",
    "    HHINCQ1\t    Households in the lowest income quartile (less than $25,000 annually in $1989)\tInteger, 0 and up\t \n",
    "    HHINCQ2\t    Households in the second lowest income quartile (between $25,000 and $45,000 in $1989)\tInteger, 0 and up\t \n",
    "    HHINCQ3\t    Households in the second highest income quartile (between $45,000 and $75,000 in $1989)\tInteger, 0 and up\t \n",
    "    HHINCQ4\t    Households in the highest income quartile (more than $75,000 in $1989)\tInteger, 0 and up\t \n",
    "    TOTACRE\t    Total acres\tFloat, 0.0 and up\t \n",
    "    RESACRE\t    Acres occupied by residential development\tInteger, 0 and up\t \n",
    "    CIACRE\t    Acres occupied by commercial or industrial development\tInteger, 0 and up\t \n",
    "    SHPOP62P\tShare of the population age 62 or older\tFloat, 0.0 to 1.00\t \n",
    "    TOTEMP\t    Total employment\tInteger, 0 and up\t \n",
    "    AGE0004\t    Persons age 0 to 4\tInteger, 0 and up\t \n",
    "    AGE0519\t    Persons age 5 to 19\tInteger, 0 and up\t \n",
    "    AGE2044\t    Persons age 20 to 44\tInteger, 0 and up\t \n",
    "    AGE4564\t    Persons age 45 to 64\tInteger, 0 and up\t \n",
    "    AGE65P\t    Persons age 65 and older\tInteger, 0 and up\t \n",
    "    RETEMPN\t    Retail trade employment (NAICS-based)\tInteger, 0 and up\t \n",
    "    FPSEMPN\t    Financial and professional services employment (NAICS-based)\tInteger, 0 and up\t \n",
    "    HEREEMPN\tHealth, educational and recreational service employment (NAICS-based)\tInteger, 0 and up\t \n",
    "    AGREMPN\t    Agricultural and natural resources employment (NAICS-based)\tInteger, 0 and up\t \n",
    "    MWTEMPN\t    Manufacturing, wholesale trade and transportation employment (NAICS-based)\tInteger, 0 and up\t \n",
    "    OTHEMPN\t    Other employment (NAICS-based)\tInteger, 0 and up\t \n",
    "    PRKCST\t    Hourly parking rate paid by long-term (8-hours) parkers (year 2000 cents)\tFloat, 0.0 and up\t \n",
    "    OPRKCST\t    Hourly parking rate paid by short-term parkers (year 2000 cents)\tFloat, 0.0 and up\t \n",
    "    AREATYPE\tArea type designation\tInteger, 0 - regional core, 1 - central business district, 2 - urban business, 3 - urban, 4 - suburban, 5 - rural\t \n",
    "    HSENROLL\tHigh school students enrolled at schools in this TAZ\tFloat, 0.0 and up\t \n",
    "    COLLFTE\t    College students enrolled full-time at colleges in this TAZ\tFloat, 0.0 and up\t \n",
    "    COLLPTE\t    College students enrolled part-time at colleges in this TAZ\tFloat, 0.0 and up\t \n",
    "    TERMINAL\tAverage time to travel from automobile storage location to origin/destination\tFloat, 0.0 and up\t \n",
    "    TOPOLOGY\tTopology (steepness) indicator\tInteger, 1 - flat, 2 - in between, 3 - steep\t \n",
    "    ZERO\t    Placeholder (always zero)\tInteger, 0\t \n",
    "    HHLDS\t    Repeat of the TOTHH variable with a different name for software compatibility\tInteger, 0 and up\t \n",
    "    SFTAZ\t    Repeat of the ZONE variable with a different name for software compatibility\tInteger, 1 to 1454\t \n",
    "    GQPOP\t    Population living in group quarters rather than households\tInteger, 0 and up\t "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing the data\n",
    "Because the populations vary significantly by TAZ, first we propbably want to <a = href = \"https://en.wikipedia.org/wiki/Normalization_(statistics)\">normalize</a> the data. For example, rather looking at the *count* of people in each income bracket, we may care more about the *percent* of people who fall into each income bracket. Say we wanted to get the percent of population that is employed per TAZ, we divide the number of employed residents by the total population for each TAZ.\n",
    "\n",
    "If we take a close look at the data, we notice that some TAZs do not have any residents. As we know, we get an error if we try to divide by zero, so first let's select only the TAZs where the total population is greater than 0. We create a new table called tazData_new."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tazData_new = tazData.where(tazData.column('TOTPOP') != 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a table for normalized data\n",
    "Let's create a new table called tazData_norm, where we store the normalized values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tazData_norm = Table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding percent employed to tazData_norm\n",
    "tazData_norm['PCTEMP']  = tazData_new['EMPRES']/tazData_new['TOTPOP']\n",
    "creates a column called 'PCTEMP' in the tazData_norm Table if it does not already exist and assigns it the values tazData_new['EMPRES']/tazData_new['TOTPOP']. \n",
    "\n",
    "tazData_norm.hist(overlay=False) creates a histogram of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tazData_norm['PCTEMP']=tazData_new['EMPRES']/tazData_new['TOTPOP']\n",
    "tazData_norm.select('PCTEMP').hist(bins = [0,.1,.2,.3,.4,.5,.6,.7,.8,.9,1.], overlay=False, normed=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Adding other normalized variable\n",
    "**Task - ** Add the following normalized columns to the table. \n",
    "\n",
    "Income: (Note for income, we want to normalize by number of households rather than total population.)\n",
    "* PCTHHINCQ1\n",
    "* PCTHHINCQ2\n",
    "* PCTHHINCQ3 \n",
    "* PCTHHINCQ4\n",
    "\n",
    "Age:\n",
    "* PCTAGE0004\n",
    "* PCTAGE0519\n",
    "* PCTAGE2044\n",
    "* PCTAGE4564\n",
    "* PCTAGE65P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create histograms of the normalized data, from the histograms find the following:\n",
    "**Task - ** Create tazData_norm histograms and use them to answer the following questions:\n",
    "* About how many TAZs have more than 20% of the population over 65 years old?\n",
    "* About how many TAZs have a medium income less than \\$25k in \\$1989?\n",
    "* About how many TAZs have a medium income greater than \\$75k in \\$1989?\n",
    "* About how many TAZ's have more than 50% employment?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Type your answers here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Part 2 - Giants Game Impact\n",
    "### Joining datatables & calculating VHT\n",
    "Imagine that 5% of the total population of the SF, Oakland, Berkeley, and Mairin area travels to AT&T park (homogeneously, assuming 5% from each TAZ). Compute the **total vehicle hours traveled (VHT)**, assuming every traveller drives alone. We'll imagine that the traffic is similar to the AM commute so you can use the data/sf_oak_TimeSkims_AM.csv from minilab3. \n",
    "\n",
    "You can use the Tables.join() function to [join](http://data8.org/datascience/_autosummary/datascience.tables.Table.join.html?highlight=join#datascience.tables.Table.join) the tables.\n",
    "\n",
    "Note that the the Giants stadium is located in TAZ 110, we need to find the travel time from each TAZ to the TAZs with dest = 110."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Your answer here:\n",
    "# Total VHT = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining datatables & calculating VMT\n",
    "With the same scenario as above (5% of the total population of the SF, Oakland, Berkeley, and Mairin area travels to AT&T park (homogeneously, assuming 5% from each TAZ)). Compute the **total vehicle miles traveled (VMT)**, to get to AT&T park assuming every traveler drives alone. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Your answer here:\n",
    "# Total VMT = \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
