{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minilab 3 - Mapping TAZ travel times\n",
    "\n",
    "In this lab we will play with some data from the Metropolitan Transportation Commission on travel time from one Traffic Analysis Zone (TAZ) to another. We will use a mapping tool called folium to create a graphical representation of travel times throughout the area.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import folium\n",
    "import json\n",
    "from datascience import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## The datasets\n",
    "### MTC travel skims\n",
    "The Metropolitan Transportation Co,mission (MTC) is the regional transportation planning organization for the Bay Area. They host a database with average travel time, cost, and distance from each traffic analysis zone (TAZ) to all other TAZs in the Bay Area. The files have data for driving alone, car pooling, walking to transit, driving to transit, walking, and biking. \n",
    "\n",
    "We have pre-processed the data from the morning commute to include only TAZs around San Francisco, Oakland and Berkeley. The files with inter-TAZ travel time, travel cost, and travel distance are saved with the following filepaths 'data/sf_oak_TimeSkims_AM.csv', 'data/sf_oak_CostSkims_AM.csv' and 'data/sf_oak_DistanceSkims_AM.csv'\n",
    "\n",
    "More info on the dataset can be found here - http://analytics.mtc.ca.gov/foswiki/Main/SimpleSkims. \n",
    "The descriptions of the columns in the data set are shown below:\n",
    "\n",
    "    orig\tOrigin transportation analysis zone\tShape file\n",
    "    dest\tDestination transportation analysis zone\tShape file\n",
    "    da\t    Door-to-door time for the drive alone travel mode (i.e. single occupant private automobile)\t \n",
    "    daToll\tDoor-to-door time for the drive alone value toll travel mode (those willing to pay to use an HOT lane)\t \n",
    "    s2\t    Door-to-door time for the shared ride 2 travel mode (i.e. double occupant private automobile)\t \n",
    "    s2Toll\tDoor-to-door time for the shared ride 2 value toll travel mode (those willing to pay to use an HOT lane)\n",
    "    s3\t    Door-to-door time for the shared ride 3+ travel mode (i.e. three-or-more occupants traveling in a private vehicle)\t \n",
    "    s3Toll\tDoor-to-door time for the shared ride 3+ value toll travel mode (those willing to pay to use an HOT lane, if scenario policy dictates they must pay)\t \n",
    "    walk\tDoor-to-door time for walking\t \n",
    "    bike\tDoor-to-door time for bicycling\t \n",
    "    wTrnW\tDoor-to-door time for walk to transit to walk paths\t \n",
    "    dTrnW\tDoor-to-door time for drive to transit to walk paths\t \n",
    "    wTrnD\tDoor-to-door time for walk to transit to drive paths (returning home on a park-and-ride tour)\n",
    "\n",
    "(The raw data with all bay area TAZs can be found at https://mtcdrive.app.box.com/2015-03-116)\n",
    "\n",
    "### Bay area TAZ geometry data\n",
    "GeoJSON is a format used for encoding a variety of geographic data structures. We have saved a GeoJSON file with the Traffic Analysis Zone (TAZ) polygons for the TAZs in the San Francisco, Oakland, and Berkeley region. We will use a mapping package called folium to map the TAZs.\n",
    "\n",
    "### Read the data\n",
    "Normally in the data 8 class we read the datasets into Tables, but for this lab we are using a  tool that requires the data to be in a Pandas Dataframe. The functionality is **very** similar to the table functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping the TAZs\n",
    "We will use a mapping package called Folium to map the TAZs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Travel time from one TAZ to all others\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Folium allows us to color map the elemets based on data. We will again use folium's geo_json() method, but now we will use additional arguments to color the TAZs based on travel time. \n",
    "We will use the following inputs to the geojson method:\n",
    "\n",
    "    data: Pandas DataFrame or Series, default None\n",
    "        Data to bind to the GeoJSON.\n",
    "    columns: the columns of the dataframe that we will use to color the data\n",
    "    key_on: string, default None\n",
    "        Variable in the GeoJSON file to bind the data to. Must always\n",
    "        start with 'feature' and be in JavaScript objection notation.\n",
    "        Ex: 'feature.id' or 'feature.properties.statename'. \n",
    "    threshold_scale: list, default None\n",
    "        Data range for D3 threshold scale. Defaults to the following range\n",
    "        of quantiles: [0, 0.5, 0.75, 0.85, 0.9], rounded to the nearest\n",
    "        order-of-magnitude integer. Ex: 270 rounds to 200, 5600 to 6000.\n",
    "    fill_color: string, default 'blue'\n",
    "        Area fill color. Can pass a hex code, color name, or if you are\n",
    "        binding data, one of the following color brewer palettes:\n",
    "        'BuGn', 'BuPu', 'GnBu', 'OrRd', 'PuBu', 'PuBuGn', 'PuRd', 'RdPu',\n",
    "        'YlGn', 'YlGnBu', 'YlOrBr', and 'YlOrRd'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "File b'data/sf_oak_TimeSkims_AM.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mOSError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-4c786346984c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Read the timeskims datafile\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/sf_oak_TimeSkims_AM.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/conda/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    560\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    561\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 562\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    563\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    564\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/conda/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 315\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/conda/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    643\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 645\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/conda/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m    797\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    798\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 799\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    800\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    801\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/conda/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1211\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1213\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas/parser.c:3427)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas/parser.c:6861)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: File b'data/sf_oak_TimeSkims_AM.csv' does not exist"
     ]
    }
   ],
   "source": [
    "#INPUTS\n",
    "origin_taz_id=10\n",
    "mode = 'bike'\n",
    "\n",
    "\n",
    "\n",
    "# Read the timeskims datafile\n",
    "data = pd.read_csv('data/sf_oak_TimeSkims_AM.csv')\n",
    "\n",
    "\n",
    "# Read the GeoJson file save the data as a string\n",
    "# json.dumps() dumps the data to a string\n",
    "geojson_data = json.load(open('data/SF_Oak_TAZs.geojson'))\n",
    "geojson_str = json.dumps(geojson_data) \n",
    "\n",
    "\n",
    "# save a new data frame that contains only rows with the origin specified above \n",
    "data_origin = data[data['orig']==origin_taz_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "traveltime_map = folium.Map(width=650, height=500, zoom_start=11,\n",
    "                            location=[37.8062449,-122.371983])\n",
    "\n",
    "traveltime_map.geo_json(geo_str=geojson_str, data=data_origin,\n",
    "                        columns=['dest', 'bike'],\n",
    "                        threshold_scale=[10,20,30,40,50],\n",
    "                        key_on='feature.properties.TAZ1454',\n",
    "                        fill_color='PuBu', fill_opacity=.8)\n",
    "\n",
    "traveltime_map.create_map('map2.html')\n",
    "traveltime_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color the origin TAZ red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# find origin_taz_id and color it red\n",
    "for i in range(len(geojson_data['features'])):\n",
    "    if (geojson_data['features'][i]['properties']['TAZ1454'] == origin_taz_id):\n",
    "        origin_feature  = geojson_data['features'][i]\n",
    "\n",
    "# Create a new geojson layer called origin_data. This geojson will only have one feature -\n",
    "# the origin feature. We will replace the origin_data['features'] with a list containing \n",
    "# only the origin TAZ feature\n",
    "\n",
    "origin_data = json.load(open('data/SF_Oak_TAZs.geojson'))\n",
    "origin_data['features']=[origin_feature]\n",
    "origin_str = json.dumps(origin_data)\n",
    "\n",
    "traveltime_map.geo_json(geo_str=origin_str,fill_color='Red',\n",
    "                       fill_opacity = .8)\n",
    "\n",
    "traveltime_map.create_map('map3.html')\n",
    "traveltime_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 - Modify the map\n",
    " <li>Change the map color scheme.\n",
    " <li>Choose an Eastbay TAZ as the origin TAZ (e.g. TAZ 1035) and generate a new map with travel times from this TAZ.\n",
    " <li>The map is currently displaying average drive alone (da) travel time from one TAZ to another. Change the travel mode to walk-transit-walk (wTrnW)\n",
    " <li>Change the color threshold values so that the color transitions happen at appropriate intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 - The relationship between spatial proximity and travel time\n",
    "For each of the following modes: drive, walk to transit, drive to transit, bike, and walk, do you think a straightline distance from one TAZ to another is a good indicator of travel time? Explain why or why not.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Task 3 - Color all unreachable TAZs grey\n",
    "For the datasets provided, MTC follows a convention of setting travel time = '-999' in the data table if they have determined that a mode is not feasible to get from an origin TAZ to a destination TAZ. For example, a bike trip from San Francisco to Oakland is not possible because bikes are not allowed accross the Bay Bridge. Similarly some walk distances are determined to be too far to make a trip on foot.\n",
    "\n",
    "Color all TAZs with a travel time of -999 grey. Hint - use a procedure similar to the procedure used to color the origin red.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3 Solution\n",
    "\n",
    "## Step 1. Find ids of destinations to color grey\n",
    "The code below finds the destination ids in one line, below this we will walk through exactly what this line is doing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find items in the data_origin dataframe that have a travel time by bike of -999\n",
    "# Below is a one-line solution to do this:\n",
    "grey_dest_ids  = data_origin[data_origin['bike'] == -999]['dest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#BUT, let's walk through it\n",
    "# Let's look at the data_origin table again\n",
    "# head() prints the first 5 rows of the dataframe\n",
    "data_origin.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# to get a list of true/false for whether bike travel time = -999\n",
    "data_origin['bike'] == -999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#grab the rows from the data_origin table where travel time by bike =-999. \n",
    "data_origin[data_origin['bike'] == -999]\n",
    "\n",
    "# Note that all bike travel times are -999 in the table printed below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now we want a list of the destination ids where bike travel time = -999\n",
    "data_origin[data_origin['bike'] == -999]['dest']\n",
    "\n",
    "# the left columm of the table printed below is the index from the initial data table. \n",
    "# The right column is the destination id column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we assign this to a variable called grey_dest_ids\n",
    "grey_dest_ids  = data_origin[data_origin['bike'] == -999]['dest']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a list of destination ids for destinations that are unreachable from the origin. \n",
    "## Step 2. Find the grey_dest_ids in the geojson file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First start with an empty list of grey_features. We will append grey features \n",
    "# to them as we find them\n",
    "grey_features = []\n",
    "\n",
    "#loop through the destination ids\n",
    "for dest_id in grey_dest_ids:\n",
    "    \n",
    "    # The code below is looping through the geojson features and finding features \n",
    "    # where the TAZ1454 property is equal to dest_id. Once it finds it, we append\n",
    "    # it to the grey_features list. (Note the 'TAZ1454' property contains the TAZ id. \n",
    "    # 'TAZ1454' refers to the fact that in total there are 1454 TAZs in the bay area,\n",
    "    # and they are assigned ids from 1 to 1454)\n",
    "    for i in range(len(geojson_data['features'])):\n",
    "        if (geojson_data['features'][i]['properties']['TAZ1454'] == dest_id):\n",
    "            grey_features.append(geojson_data['features'][i]) \n",
    "\n",
    "# Let's take a look at what grey features looks like\n",
    "grey_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Create a new Geojson object. Replace the features data with the grey_features list we just created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a new geojson layer called grey_data. We will replace the features in this\n",
    "# geojson with the list of features we just created above.\n",
    "grey_data = json.load(open('data/SF_Oak_TAZs.geojson'))\n",
    "grey_data['features']=grey_features\n",
    "grey_str = json.dumps(grey_data)\n",
    "\n",
    "#Now we add this layer to our map. Set the fill color to Grey\n",
    "traveltime_map.geo_json(geo_str=grey_str,fill_color='Grey',\n",
    "                       fill_opacity = .8)\n",
    "\n",
    "# And create the map:\n",
    "traveltime_map.create_map('map4.html')\n",
    "traveltime_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "# Task 4 - Map travel cost from an origin \n",
    "We have been visualizing travel time from one TAZ to another. As mentioned above MTC also provides info on travel cost and distance from one TAZ to another by mode. Create a folium map of tavel distance from an origin TAZ to all others, using the same procedure as outlined above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4 solution\n",
    "To do this we would run all of the same code as above, but in the very beginning, \n",
    "set data = pd.read_csv('data/sf_oak_CostSkims_AM.csv') where we use the cost\n",
    "skims file rather than the distance skims file."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
